<script>
  const langMap = {
    en: "English", es: "Spanish", fr: "French", de: "German", zh: "Chinese (Simplified)", hi: "Hindi",
    ar: "Arabic", ru: "Russian", ja: "Japanese", pt: "Portuguese", it: "Italian"
  };
  const langCodeMap = {
    en: "en-US", es: "es-ES", fr: "fr-FR", de: "de-DE", zh: "zh-CN", hi: "hi-IN",
    ar: "ar-SA", ru: "ru-RU", ja: "ja-JP", pt: "pt-PT", it: "it-IT"
  };
  const inputLang = document.getElementById('inputLang');
  const outputLang = document.getElementById('outputLang');
  const inputText = document.getElementById('inputText');
  const translatedText = document.getElementById('translatedText');
  const clearBtn = document.getElementById('clearBtn');
  const speakBtn = document.getElementById('speakBtn');
  const autoListenBtn = document.getElementById('autoListenBtn');

  let recognition = null;
  let isListening = false;

  // Voice Assistant Core
  function startAssistant() {
    if (!('webkitSpeechRecognition' in window)) {
      alert('Speech recognition not supported in this browser.');
      return;
    }
    if (recognition) {
      recognition.abort();
      recognition = null;
    }
    recognition = new webkitSpeechRecognition();
    recognition.lang = langCodeMap[inputLang.value] || "en-US";
    recognition.interimResults = false;
    recognition.maxAlternatives = 1;
    isListening = true;

    autoListenBtn.textContent = "Assistant Listening... (Click to stop)";
    autoListenBtn.classList.add('active');
    autoListenBtn.disabled = false;

    recognition.onresult = async (event) => {
      const spokenText = event.results[0][0].transcript.trim();
      await processVoiceCommand(spokenText);
      // Wait until speaking is done, then listen again
      if (isListening) {
        waitForSpeechEnd().then(() => {
          if (isListening) setTimeout(() => recognition.start(), 400);
        });
      }
    };
    recognition.onend = () => {
      // Only auto-restart if assistant is active
      if (isListening && !window.speechSynthesis.speaking) {
        setTimeout(() => recognition.start(), 400);
      }
    };
    recognition.onerror = (event) => {
      if (event.error !== "no-speech" && event.error !== "aborted") {
        alert("Speech error: " + event.error);
      }
      if (isListening) {
        setTimeout(() => recognition.start(), 700);
      }
    };
    recognition.start();
  }

  function stopAssistant() {
    isListening = false;
    if (recognition) recognition.abort();
    autoListenBtn.textContent = "Start Assistant";
    autoListenBtn.classList.remove('active');
    autoListenBtn.disabled = false;
  }

  autoListenBtn.onclick = () => {
    if (isListening) {
      stopAssistant();
    } else {
      startAssistant();
    }
  };

  // Wait until all TTS speech finishes
  function waitForSpeechEnd() {
    return new Promise(resolve => {
      if (!('speechSynthesis' in window)) return resolve();
      if (!window.speechSynthesis.speaking) return resolve();
      let id = setInterval(() => {
        if (!window.speechSynthesis.speaking) {
          clearInterval(id);
          resolve();
        }
      }, 100);
    });
  }

  // Voice Command Parsing + Actions
  async function processVoiceCommand(spokenText) {
    // 1. "translate <PHRASE> from <LANG1> to <LANG2>"
    const fromToRegex = /translate (.+?) from ([a-z]+) to ([a-z]+)/i;
    let match = spokenText.match(fromToRegex);
    if (match) {
      const phrase = match[1].trim();
      const fromLang = match[2];
      const toLang = match[3];
      let fromCode = null, toCode = null;
      for (const [code, name] of Object.entries(langMap)) {
        if (name.toLowerCase().includes(fromLang)) fromCode = code;
        if (name.toLowerCase().includes(toLang)) toCode = code;
      }
      if (fromCode) inputLang.value = fromCode;
      if (toCode) outputLang.value = toCode;
      inputText.value = phrase;
      await translateAndSpeak();
      return;
    }

    // 2. "translate <PHRASE> to <LANG2>" or "how do you say <PHRASE> in <LANG2>"
    const translateRegex = /(translate|say|how do you say) (.+?)( to | into | in )([a-z]+)$/i;
    match = spokenText.match(translateRegex);
    if (match && match[2]) {
      let phrase = match[2].trim();
      let userLang = match[4];
      if (userLang) {
        for (const [code, name] of Object.entries(langMap)) {
          if (name.toLowerCase().includes(userLang)) {
            outputLang.value = code;
          }
        }
      }
      inputText.value = phrase;
      await translateAndSpeak();
      return;
    }

    // 3. "change language to <LANG2>"
    const changeLangRegex = /(change|set|switch)( (target|output))? language (to|into|as)?\s*([a-z]+)/i;
    match = spokenText.match(changeLangRegex);
    if (match) {
      const userLang = match[6];
      for (const [code, name] of Object.entries(langMap)) {
        if (name.toLowerCase().includes(userLang)) {
          outputLang.value = code;
          speak(`Target language changed to ${name}`, inputLang.value);
          return;
        }
      }
      speak("Sorry, I couldn't find that language.", inputLang.value);
      return;
    }

    // 4. "stop assistant"
    if (/stop (assistant|listening|bot)/i.test(spokenText)) {
      speak("Stopping assistant. Goodbye.", inputLang.value);
      stopAssistant();
      return;
    }

    // 5. Just treat as text to translate
    inputText.value = spokenText;
    await translateAndSpeak();
  }

  async function translateAndSpeak() {
    const text = inputText.value.trim();
    const targetLanguage = outputLang.value;
    translatedText.innerText = ""; // clear first
    if (!text) return;
    try {
      const res = await fetch('https://nova-translator-backend.onrender.com/translate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text, targetLanguage })
      });
      const data = await res.json();
      if (data.translatedText) {
        translatedText.innerText = data.translatedText;
        speak(data.translatedText, targetLanguage);
      } else {
        translatedText.innerText = "Translation failed: " + (data.error || "Unknown error");
        speak("Sorry, translation failed.", inputLang.value);
      }
    } catch (err) {
      translatedText.innerText = "Network or server error: " + err.message;
      speak("Sorry, network or server error.", inputLang.value);
    }
  }

  function speak(text, lang) {
    if ('speechSynthesis' in window && text) {
      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = langCodeMap[lang] || lang || "en-US";
      utter.rate = 1.03;
      utter.volume = 1;
      window.speechSynthesis.cancel();
      window.speechSynthesis.speak(utter);
    }
  }

  speakBtn.onclick = () => { speak(translatedText.innerText, outputLang.value); };
  clearBtn.onclick = () => {
    inputText.value = '';
    translatedText.innerText = '';
    inputText.focus();
  };

  // Optionally: Listen for ENTER key to trigger translation (desktop)
  inputText.addEventListener("keydown", function(event) {
    if (event.key === "Enter" && !event.shiftKey) {
      event.preventDefault();
      translateAndSpeak();
    }
  });

  // Optional: Start assistant immediately if desired (but requires user gesture per browser rules)
  // window.onload = () => { startAssistant(); };
</script>
